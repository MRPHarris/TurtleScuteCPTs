---
title: "Monte-carlo changepoints of turtle scute growth rates"
author: Matt Harris m.harris@gns.cri.nz
output: word_document
fontsize: 11pt
sansfont: Times New Roman
---

```{r setup, echo = FALSE, messages = FALSE ,results = 'hide', warning = FALSE, message = FALSE}
## SETUP CHUNK
# rmd pandoc check
rmarkdown::find_pandoc(version = "2.17.0.1")
# knitr stuff
knitr::opts_chunk$set(fig.align = 'center')

## Load required packages
## get devtools and pacman
# install_packages('devtools')
# install_pacakges('pacman')

## Github install + uninstall lines if needed
# detach(package:MCCPT, unload = TRUE)
# installr::uninstall.packages("MCCPT")

## Github install lines
##
## YOU MUST INSTALL MCCPT AND turtleCPTs TO USE THIS NOTEBOOK
##
# devtools::install_github("hcadd/MCCPT@main")
# devtools::install_github("MRPHarris/turtleCPTs@main")

## Pacman loading
library(pacman)
pacman::p_load(tidyverse, dplyr, magrittr, here, 
               MCCPT, 
               turtleCPTs,
               cowplot,rlist,fs,matrixStats,openxlsx, ggtext, pracma, scales, RColorBrewer)

## directories
proj_dir <- paste0(here(),"/")
setwd(proj_dir)
data_raw <- paste0(proj_dir,"data-raw/")
img_dir <- paste0(proj_dir,"images-and-figures/")
log_dir <- paste0(proj_dir,"results-MCCPT-logs-and-criteria/")

## Load example turtle
tdat_13987 <- load_turtle_raw(paste0(data_raw,"Turtle_13987_2000ENS.csv"))

## Generalise turtle assignment for figs (can change turtle more easily if needed)
tdat_indiv <- tdat_13987

## All example turtle data
turtle_data <- import_files(paste0(proj_dir,"results-MCCPT-for-writeup/formatted sed data/"))
CPT_data_examples <- get_CPT_files(target_folder = paste0(here::here(),"/results-MCCPT-for-writeup/MCCPT files/"))
CPT_data_all <- get_CPT_files(target_folder = paste0(here::here(),"/results-MCCPT-changepoints/"))
suffix = ""

## Overall data
# Classification criteria
cpt_classes <- openxlsx::read.xlsx(paste0(log_dir,"change-classification-criteria.xlsx"),1)

# Turtle results - contains exclusion data
turtle_res_log <- read.csv(paste0(log_dir,"Turtle-CPT-results-all-changes.csv"))

# Turtle cpt assignments
assignments <- read.csv(paste0(log_dir,'turtle-changepoints-classified-10pct-stable.csv')) %>%
  mutate(exclusion_combos = paste0(turtle," ",CPT))

# Turtle species and locations
Turtle_info <- read.csv(paste0(log_dir,"Turtle species and location.csv")) %>%
  relocate(ID)

# Start and end of red tide (NOAA)
rt2018_start = decimal_date(ym("2017-10"))
rt2018_end = decimal_date(ym("2019-01"))

# Start end end of the two large sargassum blooms (from Wang et al., 2019)
sg2015_start = decimal_date(ym("2014-11"))
sg2015_end = decimal_date(ym("2016-02"))
sg2018_start = decimal_date(ym("2017-11"))
sg2018_end = decimal_date(ym("2018-11"))

## Addnl plotting elements
textsize_normal = 9 * 2.35
textsize_small  = 8 * 2.3
textsize_vsmall = 7 * 2.25
theme_rem_xaxis <- theme(
  axis.text.x = element_blank(),
  axis.line.x = element_blank(),
  axis.title.x = element_blank(),
  axis.ticks.x = element_blank()
)

```

This document provides a writeup of the work done to analyse scute radiocarbon-derived turtle growth rates for Linscott & Wallace et al. (2026), accepted for publication in Marine Biology. The text here may be less up-to-date than that included in the manuscript and its SI.

When using any of the code used to generate this document (i.e., in the .Rmd file), in the [TurtleScuteCPTs](github.com/MRPHarris/TurtleScuteCPTs) repository, or from the [turtleCPTs](github.com/MRPHarris/turtleCPTs) helper package, cite the above paper. 

## MCCPT Methods

We sought to better constrain the timing of changes identified in the turtle scute growth rates. In order to empirically identify instances of significant change in the scute records, we applied changepoint analysis to the growth rates, incorporating age uncertainty by analysing changes across ensemble members from the Bayesian age model for each turtle. We utilised the MCCPT R package (Cadd et al., 2021), an adaptation of the Killick & Eckley (2014) implementation of changepoint analysis in R (R core team, 2024). We generated probability density functions (PDFs) for changepoints in sedimentation rates identified across 2000 age model iterations generated by the Oxcal. 

The method applied for Monte-Carlo changepoint analysis is described in Cadd et al. (2021). It applies the Killick changepoint method (Killick & Eckley, 2014) across age model ensemble members, providing a PDF of changepoint locations for a given record. Density estimates are given by unweighted, guassian kernel density estimation. We adapted the approach for use on turtle scute radiocarbon dates. All code developed for the approach can be found in the repository at [github.com/MRPHarris/TurtleScuteCPTs](github.com/MRPHarris/TurtleScuteCPTs) and the helper R package [turtleCPTs](github.com/MRPHarris/turtleCPTs). 

We take advantage of the high-resolution, sub-annually resolved radiocarbon dates by interpolating the radiocarbon profiles (including age model members and oxcal-estimated poisson-corrected sedimentation rates) to 1 micron resolution. 

## Age model interpolation

Age model ensemble members (n = 2000) for each turtle were first interpolated to a resolution of 1 micron in order to provide a consistent depth resolution. We experimented with both linear and monotonic cubic spline interpolation (Hyman, 1983). An example for a single turtle (T13987) is shown below.

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 6, fig.width = 14, units = cm}

## turtle 12951 to start
# tdat_indiv <- tdat_13987

## Interpolate: linear
tdat_indiv_linterp <- turtle_age_interp(tdat_indiv)$linear %>%
  'colnames<-'(c("Depth",seq(1,2000,1))) %>% 
  pivot_longer(cols = c(2:ncol(.)))

## Interpolate: monotonic spline
tdat_indiv_splnterp <- turtle_age_interp(tdat_indiv)$spline %>%
  'colnames<-'(c("Depth",seq(1,2000,1))) %>% 
  pivot_longer(cols = c(2:ncol(.)))#

## ensemble cols to numeric
names_numeric <- unlist(lapply(strsplit(colnames(tdat_indiv$ens),"_"),"[[",2)) %>% as.numeric()

## Need to also interpolate the oxcal +/- bounds
interp_vec = seq(min(tdat_indiv$cal$z),max(tdat_indiv$cal$z), 1)
tdat_bounds <- calc_sa_bounds(tdat_indiv$ens,tdat_indiv$bounds)
tdat_upper_lin = approx(x = tdat_bounds$z, y = tdat_bounds$b95, xout = interp_vec) %>% as.data.frame() %>% 'colnames<-'(c('z','b95'))
tdat_lower_lin = approx(x = tdat_bounds$z, y = tdat_bounds$a5, xout = interp_vec) %>% as.data.frame() %>% 'colnames<-'(c('z','a5'))
tdat_upper_spln = spline(x = tdat_bounds$z, y = tdat_bounds$b95, xout = interp_vec, method = 'hyman') %>% as.data.frame() %>% 'colnames<-'(c('z','b95'))
tdat_lower_spln = spline(x = tdat_bounds$z, y = tdat_bounds$a5, xout = interp_vec, method = 'hyman') %>% as.data.frame() %>% 'colnames<-'(c('z','a5'))

## And the intcal t for good measure
intcal_t_lin = approx(x = tdat_indiv$cal$z, y = tdat_indiv$cal$intcal20_t, xout = interp_vec) %>% as.data.frame() %>% 'colnames<-'(c('z','intcal20_t'))
intcal_t_spln = spline(x = tdat_indiv$cal$z, y = tdat_indiv$cal$intcal20_t, xout = interp_vec, method = 'hyman') %>% as.data.frame() %>% 'colnames<-'(c('z','intcal20_t'))

## Plotting
p_lin <- ggplot() + 
  geom_vline(xintercept = c(seq(0,500,100),541), colour = 'grey60', alpha = 0.4) +
  geom_vline(xintercept = seq(2010,2022,1), colour = 'grey60', alpha = 0.4) +
  geom_line(data = tdat_indiv_linterp, aes(x = value, y = Depth, group = name, colour = as.numeric(name))) +
  geom_line(data = tdat_upper_lin, aes(x = b95, y = z), colour = 'black', linewidth = 1.5, alpha = 0.8) +
  geom_line(data = tdat_lower_lin, aes(x = a5, y = z), colour = 'black',  linewidth = 1.5, alpha = 0.8) +
  geom_line(data = intcal_t_lin, aes(x = intcal20_t, y = z), colour = 'red',  linewidth = 1.5, alpha = 0.8) +
  geom_point(data = tdat_indiv$cal, aes(x = intcal20_t, y = z), colour = 'black', fill = 'red', shape = 21, size = 2.5) +
  labs(x = "Year", y = "z (&mu;m)", colour = "Age model n") +
  annotate(geom = "text", label = "A", x = 2014, y = 25, size = 9) + 
       # title = "1 &mu;m linear") + 
  scale_y_reverse(expand = c(0,0), limits = c(543,-2), breaks = c(seq(0,500,100),541)) +
  scale_x_continuous(expand = c(0,0), limits = c(1990,2023), breaks = seq(1990,2023,1)) +
  scale_colour_viridis_c(option = 'viridis', alpha = 0.8, direction = -1, breaks = c(1,seq(500,2000,500))) +
  theme_main(textsize_small) +
  theme(plot.margin = margin(7,10,7,7),
        legend.position = 'inside',
        legend.position.inside = c(0.7,0.3),
        legend.box.background = element_rect(fill = 'white',colour = 'white')) +
  coord_cartesian(xlim = c(2013.5,2023))
#
p_spln <- ggplot() + 
  geom_vline(xintercept = c(seq(0,500,100),541), colour = 'grey60', alpha = 0.4) +
  geom_vline(xintercept = seq(2010,2022,1), colour = 'grey60', alpha = 0.4) +
  geom_line(data = tdat_indiv_splnterp, aes(x = value, y = Depth, group = name, colour = as.numeric(name))) +
  geom_line(data = tdat_upper_spln, aes(x = b95, y = z), colour = 'black', linewidth = 1.5, alpha = 0.8) +
  geom_line(data = tdat_lower_spln, aes(x = a5, y = z), colour = 'black',  linewidth = 1.5, alpha = 0.8) +
  geom_line(data = intcal_t_spln, aes(x = intcal20_t, y = z), colour = 'red',  linewidth = 1.5, alpha = 0.8) +
  geom_point(data = tdat_indiv$cal, aes(x = intcal20_t, y = z), colour = 'black', fill = 'red', shape = 21, size = 2.5) +
  labs(x = "Year", y = "z (&mu;m)", colour = "Age model n") +
  annotate(geom = "text", label = "B", x = 2014, y = 25, size = 9) + 
  scale_y_reverse(expand = c(0,0), limits = c(543,-2), breaks = c(seq(0,500,100),541)) +
  scale_x_continuous(expand = c(0,0), limits = c(1990,2023), breaks = seq(1990,2023,1)) +
  scale_colour_viridis_c(option = 'viridis', alpha = 0.8, direction = -1, breaks = c(1,seq(500,2000,500))) +
  theme_main(textsize_small) +
  theme(plot.margin = margin(7,25,7,7),
        legend.position = 'none') +
  coord_cartesian(xlim = c(2013.5,2023))

cowplot::plot_grid(p_lin,p_spln,
                   nrow = 1, ncol = 2,
                   align = 'h')

```

Age model interpolation for T13987. (A) Linear interpolation between radiocarbon dates. (B) As in A, but with monotonic cubic spline interpolation. Individual ensemble members are shown as coloured lines. The 95th and 5th percentile of ensemble ages are shown as dark grey lines. Red points denote oxcal age estimates ('t'), with interpolated values as a red line. The age estimates (red points) also indicate the sampling interval, with values between these points on all ensemble members being interpolated.

## Growth rate interpolation

In order to quantify probability of changes in growth rates, the sedimentation rate esimates provided by oxcal were interpolated to the same resolution as the age model ensembles (1 um). An example for the same turtle, T13987, is shown below. Interpolation was performed using both a linear and cubic (non-montonic) spline method (Forsythe et al., 1977).

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 6, fig.width = 14, units = cm}

## Sed rates interpolated using linear and spline methods

# Get sed rates for our example turtle, 12951.
tdat_indiv_sed <- tdat_indiv$sed

## Slightly out of order compared to last plot: intcal t interp first
intcal_t_lin = approx(x = tdat_indiv$cal$z, y = tdat_indiv$cal$intcal20_t, xout = interp_vec) %>% as.data.frame() %>% 'colnames<-'(c('z','intcal20_t'))
intcal_t_spln = spline(x = tdat_indiv$cal$z, y = tdat_indiv$cal$intcal20_t, xout = interp_vec, method = 'hyman') %>% as.data.frame() %>% 'colnames<-'(c('z','intcal20_t'))

## Cubic spline from Forsythe, G. E., Malcolm, M. A. and Moler, C. B. (1977). Computer Methods for Mathematical Computations. Wiley.
tdat_sed_lin <- turtle_sed_interp(tdat_indiv)$linear %>%
  mutate(intcal20_t = intcal_t_lin$intcal20_t)
tdat_sed_spln <- turtle_sed_interp(tdat_indiv, spline_method = "fmm")$spline%>%
  mutate(intcal20_t = intcal_t_spln$intcal20_t)

## Add all the age models! 

## Interpolate: linear
tdat_indiv_linterp_sed <- turtle_age_interp(tdat_indiv)$linear %>%
  'colnames<-'(c("Depth",seq(1,2000,1))) %>%
  mutate(sed = tdat_sed_lin$sed) %>%
  select(-c(Depth)) %>% relocate(sed) %>%
  pivot_longer(cols = c(2:ncol(.)))

## Interpolate: monotonic spline
tdat_indiv_splnterp_sed <- turtle_age_interp(tdat_indiv)$spline %>%
  'colnames<-'(c("Depth",seq(1,2000,1))) %>% 
  mutate(sed = tdat_sed_spln$sed) %>%
  select(-c(Depth)) %>% relocate(sed) %>%
  pivot_longer(cols = c(2:ncol(.)))

## Bounds
## Need to also interpolate the oxcal +/- bounds
interp_vec = seq(min(tdat_indiv$cal$z),max(tdat_indiv$cal$z), 1)
tdat_bounds <- calc_sa_bounds(tdat_indiv$ens,tdat_indiv$bounds)
## linear
tdat_upper_lin_sed = approx(x = tdat_bounds$z, y = tdat_bounds$b95, xout = interp_vec) %>% as.data.frame() %>% 'colnames<-'(c('z','b95')) %>% mutate(sed = tdat_sed_lin$sed)
tdat_lower_lin_sed = approx(x = tdat_bounds$z, y = tdat_bounds$a5, xout = interp_vec) %>% as.data.frame() %>% 'colnames<-'(c('z','a5')) %>% mutate(sed = tdat_sed_lin$sed)
## Spline
tdat_upper_spln_sed = spline(x = tdat_bounds$z, y = tdat_bounds$b95, xout = interp_vec, method = 'hyman') %>% as.data.frame() %>% 'colnames<-'(c('z','b95')) %>% mutate(sed = tdat_sed_spln$sed)
tdat_lower_spln_sed = spline(x = tdat_bounds$z, y = tdat_bounds$a5, xout = interp_vec, method = 'hyman') %>% as.data.frame() %>% 'colnames<-'(c('z','a5')) %>% mutate(sed = tdat_sed_spln$sed)

## Plots
p_sed_lin <- ggplot() + 
  geom_vline(xintercept = seq(0,200,50), colour = 'grey60', alpha = 0.4) +
  geom_vline(xintercept = seq(2010,2022,1), colour = 'grey60', alpha = 0.4) +
  geom_line(data = tdat_indiv_linterp_sed, aes(x = value, y = sed, group = name, colour = as.numeric(name))) +
  geom_line(data = tdat_upper_lin_sed, aes(x = b95, y = sed), colour = 'black', linewidth = 1.5, alpha = 0.8) +
  # geom_line(data = tdat_lower_lin_sed, aes(x = a5, y = sed), colour = 'black',  linewidth = 1.5, alpha = 0.8) +
  geom_line(data = tdat_sed_lin, aes(x = intcal20_t, y = sed), colour = 'red', linewidth = 1.5, alpha = 1) +
  geom_point(data = tdat_indiv_sed, aes(x = intcal20_t, y = sed), colour = 'black', fill = 'red', shape = 21, size = 2.5) +
  geom_line(data = tdat_lower_lin_sed, aes(x = a5, y = sed), colour = 'black',  linewidth = 1.5, alpha = 0.8) +
  labs(x = "Year", y = "Scute growth rate (&mu;m per year)", colour = "Age model n") +
    annotate(geom = "text", label = "A", x = 2014, y = 190, size = 9) + 
       # title = "1 &mu;m linear") + 
  scale_x_continuous(expand = c(0,0), limits = c(1990,2023), breaks = seq(1990,2023,1)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,200), breaks = seq(0,200,50)) +
  scale_colour_viridis_c(option = 'viridis', alpha = 0.8, direction = -1, breaks = c(1,seq(500,2000,500))) +
  theme_main(textsize_small) +
  theme(plot.margin = margin(7,10,7,7),
        legend.position = 'inside',
        legend.position.inside = c(0.01,0.3),
        legend.box.background = element_rect(fill = 'white',colour = 'white')) +
  coord_cartesian(xlim = c(2013.5,2023))

p_sed_spln <- ggplot() + 
  geom_vline(xintercept = seq(0,200,50), colour = 'grey60', alpha = 0.4) +
  geom_vline(xintercept = seq(2010,2022,1), colour = 'grey60', alpha = 0.4) +
  geom_line(data = tdat_indiv_splnterp_sed, aes(x = value, y = sed, group = name, colour = as.numeric(name))) +
  geom_line(data = tdat_upper_spln_sed, aes(x = b95, y = sed), colour = 'black', linewidth = 1.5, alpha = 0.8) +
  # geom_line(data = tdat_lower_spln_sed, aes(x = a5, y = sed), colour = 'black',  linewidth = 1.5, alpha = 0.8) +
  geom_line(data = tdat_sed_spln, aes(x = intcal20_t, y = sed), colour = 'red', linewidth = 1.5, alpha = 1) +
  geom_point(data = tdat_indiv_sed, aes(x = intcal20_t, y = sed), colour = 'black', fill = 'red', shape = 21, size = 2.5) +
  geom_line(data = tdat_lower_spln_sed, aes(x = a5, y = sed), colour = 'black',  linewidth = 1.5, alpha = 0.8) +
  labs(x = "Year", y = "Scute growth rate (&mu;m per year)", colour = "Age model n") +
    annotate(geom = "text", label = "B", x = 2014, y = 190, size = 9) + 
       # title = "1 &mu;m linear") + 
  scale_x_continuous(expand = c(0,0), limits = c(1990,2023), breaks = seq(1990,2023,1)) +
  scale_y_continuous(expand = c(0,0), limits = c(0,200), breaks = seq(0,200,50)) +
  scale_colour_viridis_c(option = 'viridis', alpha = 0.8, direction = -1, breaks = c(1,seq(500,2000,500))) +
  theme_main(textsize_small) +
  theme(plot.margin = margin(7,25,7,7),
        legend.position = 'none') +
  coord_cartesian(xlim = c(2013.5,2023))

cowplot::plot_grid(p_sed_lin,p_sed_spln,
                   nrow = 1, ncol = 2,
                   align = 'h')

```

Growth rate interpolation for T13987. (A) Linear interpolation between radiocarbon dates. (B) As in A, but with monotonic cubic spline interpolation. Individual ensemble members are shown as coloured lines. The 95th and 5th percentile of ensemble ages are shown as dark grey lines. Red points denote oxcal age estimates ('t'), with interpolated values as a red line. The age estimates (red points) also indicate the sampling interval, with values between these points on all ensemble members being interpolated.

We utilise the spline-interpolated datasets moving forward in order to provide more realistic transitions between datapoints. Ultimately, the high sampling resolution of the turtle scute records prevents severe differences between the two interpolation methods and we did not observe any shifts in our results as a result of the interpolation method chosen.

## Monte-carlo changepoint analysis

To determine whether the observed changes in turtle growth rates were significant shifts, and whether any patterns were present across the population of turtles analysed, we conducted monte-carlo changepoint analysis of our turtles. Our analysis utilises the MCCPT R package (Cadd et al., 2021), which employs the changepoint method developed by Kilick and Eckley (2021) to identify the presence of changepoints across all ensemble members within a Bayesian age model. A kernel density estimation is then used to produce a per-turtle, per-changepoint probability density function (PDF) that quantifies the distribution of a given changepoint across all ensemble members (n = 2000) for that turtle's age model. We used the binned segment method to identify shifts in the mean interpolated turtle scute growth rates, specifying a number of segments equal to the number of radiocarbon dates for each turtle in order. We iteratively specified increasing numbers of changepoints for each record until all major observed changes were captured - that is, there were no overlapping segments in the identification of changes in mean and variance. 

Initial attempts to identify changes in the growth rates of the turtles based upon shifts in the mean growth rate were difficult, as the growth rates do not feature consistent values with distinguishable step changes for the most part. Instead, most turtles are changing their growth rates fairly continuously. This makes it difficult for the changepoint algorithms (all types listed in Killick & Eckley, 2021 were attempted) to identify changes in the growth rates. See example for T12953 below, which features a clear shift from increasing to decreasing growth rates: 

```{r, echo = FALSE, fig.width = 14, units = "cm"}
knitr::include_graphics(paste0(proj_dir,"results-MCCPT-for-writeup/images/T12953_CPT_MeanBinSeg3cpts.png"))
```

X axis is years BP 2025, with time advancing from right to left. The changepoint algorithm (binned segments of changes in mean values, in this case) is failing to detect shifts in the record, and is instead identifying points where the greatest magnitude of change is occurring, which results in a large shift in binned mean values.

To mitigate this, turtle growth rates were converted to discrete gradients. This allows shifts in the rate of growth rate changes to be quantified in a form that is more easily interrogated with the changepoint algorithms. Immediately prior to running the gradient data through the changepoint algorithm, gradient values were rescaled to between 0 and 100 in order to allow for shifts in means to be detected.

Example for the same turtle, below:

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 6, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods

# Get single turtle data
t12953_data <- turtle_data$T12953

# Extract series and then gradient
series <- t12953_data$data %>% 'colnames<-'(c("depth","sed")) %>%
  mutate(g = return_gradient(.[[2]])) %>%
  mutate(age_intcal = 2025 - t12953_data$ages$Mean) %>%
  mutate(g_rscl = scales::rescale(g, to = c(0,100)))



## Plots
# first, the growth rate
p_sed <- ggplot() + 
  geom_vline(xintercept = seq(2010,2022,1), colour = 'grey60', alpha = 0.4) +
  geom_line(data = series, aes(x = age_intcal, y = sed)) +
  labs(x = "Year", y = "Scute growth rate (&mu;m per year)") +
    # annotate(geom = "text", label = "A", x = 2014, y = 190, size = 9) + 
       # title = "1 &mu;m linear") + 
  scale_x_continuous(expand = c(0,0), limits = c(2013,2020), breaks = seq(2013,2020,1)) +
  # scale_y_continuous(expand = c(0,0), limits = c(0,200), breaks = seq(0,200,50)) +
  # scale_colour_viridis_c(option = 'viridis', alpha = 0.8, direction = -1, breaks = c(1,seq(500,2000,500))) +
  theme_main(textsize_small) +
  theme_rem_xaxis +
  theme(plot.margin = margin(7,7,0,7)) +
  coord_cartesian(xlim = c(2013,2020))

p_grad <- ggplot() + 
  geom_hline(yintercept = 0, colour = 'red') +
  geom_vline(xintercept = seq(2010,2022,1), colour = 'grey60', alpha = 0.4) +
  geom_line(data = series, aes(x = age_intcal, y = g)) +
  labs(x = "Year", y = "Growth rate gradient") +
    # annotate(geom = "text", label = "A", x = 2014, y = 190, size = 9) + 
       # title = "1 &mu;m linear") + 
  scale_x_continuous(expand = c(0,0), limits = c(2013,2020), breaks = seq(2013,2020,1)) +
  scale_y_continuous(expand = c(0,0), limits = c(-0.15,0.3), breaks = seq(-0.1,0.3,0.1), position = 'right') +
  # scale_y_continuous(expand = c(0,0), limits = c(0,200), breaks = seq(0,200,50)) +
  # scale_colour_viridis_c(option = 'viridis', alpha = 0.8, direction = -1, breaks = c(1,seq(500,2000,500))) +
  theme_main(textsize_small) +
  theme(plot.margin = margin(-5,7,7,7)) +
  coord_cartesian(xlim = c(2013,2020))


cowplot::plot_grid(p_sed,
                   p_grad,
                   nrow = 2, ncol = 1,
                   align = 'v', rel_heights = c(0.5,0.5))

```

The subannual 'wiggles' may be an artifact of the spline interpolation.

This proved far more effective at accurately identifying changepoints, with the binned segment algorithm proving highly adept at distinguishing alterations in the slope of the growth rate curves, indicating points in time where the rate of scute growth has increased or decreased:

```{r, echo = FALSE, fig.width = 14, units = "cm"}
knitr::include_graphics(paste0(proj_dir,"results-MCCPT-for-writeup/images/T12953_CPT.png"))
```

### Revamped changepoint classification

In order to compare changes within and between turtles in as consistent a manner as possible, we classified changepoints in turtle growth rates based upon (1) their 'type' - that is, what the change represents in terms of the turtle's growth dynamics (increasing rate, decreasing rate, etc.), and (2) their severity (distinguishing major from minor changes). 

Ultimately,  there are two main categories of change (essentially unchanged from the preliminary analysis):

- increasing, where the slope is positive after the change
- decreasing, where the slope is negative after the change

Within each of these categories, there are different types of change:

- accelerating (stabilising), where the slope is more (less) in the direction it was previously (increasing or decreasing).
- a reversal, where the change entails a movement between stable, increasing, or decreasing rates in adjacent segments.
- a complete reversal, where the change is from increasing to decreasing and visa versa.

This allows us to, for example, separate increasing changes into multiple categories:

- An increasing change that is accelerating, where the turtle has moved from increasing growth rates to more quickly increasing growth rates (higher slope)
- An increasing change that is stabilising, where the turtle has moved from increasing growth rates to less quickly increasing growth rates (lower slope but still positive)
- An increasing reversal, where the turtle has transitioned from decreasing to stable or stable to increasing growth rates
- An increasing complete reversal, where the turtle has transitions from decreasing to increasing growth rates.

We might only really be interested in the latter two types (reversals), but this scheme allows for a consistent separation of these types of changepoints from others - for instance, a turtle experiencing a slowing in its increase in growth (but still increasing - see bullet point 2, above) is not confused with a turtle that has transitioned from increasing to decreasing growth rates (a complete reversal). As the most major changes are the ones most likely to represent shifts of interest within and across turtle populations, this allows for big shifts (major, complete reversals) to be separated from potentially less significant changes.

This may seem exhaustive (refer to change-classification-criteria.xlsx), but it ensures that all changes are captured by the analysis. The change types we are interested in (major complete reversals, mostly) are separated from the rest in subsequent sections.

### Applying changepoint classification

To accomplish the classification, linear regressions were fit to the growth rate values for each growth rate segment (between changepoints). Changes in the slope of the regressions across each changepoint (i.e., between segments) were then calculated. In order to account for differing total growth rates between turtles, rate changes across changepoints were normalised by the total growth rate range of each turtle, expressed as a percentage. Rate units in um/year:

slope_norm = (slope/(max_rate - min_rate)) * 100

This ensures that the final PDFs are not overrepresented by turtles that grow faster overall once the thresholds outlined below are applied.

To identify periods of 'stable' growth rates (as opposed to increasing and decreasing), we applied a normalised slope threshold of +/- 10 um/year/year. Segments lying within this normalised slope range are classed as 'stable', with the turtle growing at a consistent rate during the time encompassed by the segment. We classed major changes as being those that see a change in normalised slope of >25% (where the absolute value of slope_norm exceeds 25, see above - the rate change is equivalent to 1/4 of the turtle's growth rate change over a period of 1 year). 

An example of the fitted regressions, slopes, and changepoint rate changes are illustrated using T13327 below:

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 6, fig.width = 10, units = cm}

## output_directory = paste0(proj_dir,"plots-CPT-all-changes/")
suffix = ""
turtle_dat = turtle_data$T13326
turtle_cpts = CPT_data_examples$T13326
turtle_ID = turtle_dat$metadata[,2][which(turtle_dat$metadata[,1] == "Site code")]

## Format turtle data - interpolated, from the MCCPT-formatted datasets.
tdat_ages <- turtle_dat$data %>%
  mutate(age = 2025 - turtle_dat$ages$Mean) %>% 'colnames<-'(c('depth','sed','age')) %>% 
  mutate(g = return_gradient(sed))

## Get CPT Mean locations and PDFS
# PDFs
cpt_pdfs <- turtle_cpts %>% lapply(.,function(x)(x <- x %>% select(c(x,y))))
for(c in seq_along(cpt_pdfs)){cpt_pdfs[[c]] <- cpt_pdfs[[c]] %>% mutate(CPT = as.factor(c))} 
cpt_pdfs <- cpt_pdfs %>% list.rbind(.) %>% mutate(x = 2025 - x)
# Means
cpt_means <- turtle_cpts %>% 
  lapply(.,function(x){x <- x %>% select(mean) %>% filter(!is.na(mean))}) %>% # select mean vals, filter empty rows
  list.rbind(.) %>% mutate(mean = 2025 - mean) %>% # correct the age to CE not BP2025
  mutate(CPT = as.factor(seq(1,nrow(.),1))) # Add CPT number as sequential row n

## Find CPT locations in dataset
cpt_closest_age_ind <- sapply(cpt_means$mean, function(x){
  x_nearest <- find_nearest(x, tdat_ages$age)
})
indices = c(1,cpt_closest_age_ind,nrow(tdat_ages))
age_bounds = tdat_ages$age[c(1,cpt_closest_age_ind,nrow(tdat_ages))]
segl <- vector('list',length = length(indices)-1)
for(i in seq_along(indices)){
  # i = 2
  if(i != 1){
    segl[i-1] = mean(tdat_ages$g[indices[i-1]:indices[i]])
  }
}
segl <- segl %>% list.rbind(.) %>% as.data.frame() %>% mutate(seg = seq(1,nrow(.),1)) %>%
  'colnames<-'(c('seg_mean','seg_n')) %>%
  mutate(seg_min_x = c(1,indices[2:(length(indices)-1)]+1),
         seg_max_x = c(indices[2:length(indices)][1:length(indices[2:length(indices)-2])],
                       nrow(tdat_ages)),
         seg_min_age = age_bounds[1:(length(age_bounds)-1)],
         seg_max_age = age_bounds[2:length(age_bounds)])

## Long-form data with segments identified
segs <- vector('list',length = nrow(segl))
for(s in seq_along(segs)){
  # s = 2
  seg_x = tdat_ages$age[segl$seg_min_x[s]:segl$seg_max_x[s]]
  # seg_y = normalise(tdat_ages$sed)[segl$seg_min_x[s]:segl$seg_max_x[s]]
  seg_y = tdat_ages$sed[segl$seg_min_x[s]:segl$seg_max_x[s]]
  segs[[s]] <- data.frame(seg_x,seg_y) %>% 'colnames<-'(c('age','sed')) %>% 
    mutate(segment = s)
}
segs <- segs %>% list.rbind() %>% as.data.frame() %>%
  dplyr::group_by(segment) %>%
  mutate(weeks_from_zero = 52 * (age - min(age))) %>%
  mutate(months_from_zero = 12 * (age - min(age))) %>%
  mutate(years_from_zero = 1 * (age - min(age)))

## Fit linear models iteratively to segments
lms <- vector('list',length = nrow(segl)) %>% 'names<-'(c(paste0('seg-',seq(1,nrow(segl),1))))
for(seg in seq_along(lms)){
  # seg_x = tdat_ages$age[segl$seg_min_x[seg]:segl$seg_max_x[seg]]
  seg_x = segs$years_from_zero[segl$seg_min_x[seg]:segl$seg_max_x[seg]]
  seg_y = segs$sed[segl$seg_min_x[seg]:segl$seg_max_x[seg]]
  lms[[seg]] <- lm(seg_y ~ seg_x)
}

## Get slopes from all the models and differences between them
slopes <- lapply(lms,function(x){x_grad <- x$coefficients[2]}) %>% unlist()
# Differences are always calculated advancing with time (i.e. last to first cpts)
slope_diffs <- rev(diff(rev(slopes)))

## Summaries by CPT
cpt_summary <- cpt_means %>% 
  mutate(rate_change = rev(diff(rev(slopes)))) %>%
  mutate(rate_change_norm = rate_change/diff(c(min(tdat_ages$sed),max(tdat_ages$sed))) * 100)

## Summaries by segment
seg_summary <- slopes %>% as.data.frame() %>% 'colnames<-'(c('um_peryear_peryear')) %>%
  mutate(segment = seq(1,nrow(.),1)) %>%
  relocate(segment) %>%
  mutate(type = ifelse(abs(slopes) < 5,
                       yes = "stable",
                       no = ifelse(sign(slopes) == -1,
                                   yes = "decreasing",
                                   no = "increasing"))) 

## Classification (much of the above code but wrapped - see fn script)
cpt_info <- classify_changepoints(turtle_dat = turtle_dat,
                                  turtle_cpt_data = turtle_cpts,
                                  cpt_class_criteria = cpt_classes,
                                  stable_segment_threshold = 5,
                                  major_change_threshold = 25)

# Palette?
pal <- brewer.pal(n = nrow(cpt_means), name = "Dark2")

# Plot CPTS
# Three plots; sed rate, gradients with segments, then PDFs. All with carryover lines.
p_sed <- ggplot() +
  geom_line(data = tdat_ages, aes(x = age, y = sed), linewidth = 1) + 
  # scale_colour_manual(values = pal) +
  # scale_fill_manual(values = pal) +  
  annotate(geom = 'text', x = cpt_means$mean + (1/12) * 2, y = c(125,155,215,255,200), label = seq(1,5,1),
           size = textsize_vsmall/.pt) +
  # annotate(geom = 'text', x = 2018, hjust = 0, 
  #          y = seq(175,225,(225-175)/4), 
  #          label = paste0(rev(seq(1,5,1)),
  #                         "     |     ",  rev(round(cpt_summary$rate_change_norm,3))),
  #          size = textsize_vsmall/.pt) +
  geom_vline(data = cpt_means, aes(xintercept = mean, colour = fct_inorder(CPT)), linetype = 'solid', linewidth = 1) +
  scale_colour_manual(values = pal) +
  scale_fill_manual(values = pal) +
  scale_x_continuous(expand = c(0,0), limits = c(min(tdat_ages$age),max(tdat_ages$age))) +
  # scale_x_continuous(expand = c(0,0), limits = c(min(tdat_ages$age),max(tdat_ages$age))) +
  scale_y_continuous(expand = c(0,0), limits = c(100,260), breaks = seq(100,250,50)) +
  geom_line(stat = 'smooth', data = segs, aes(x = age, y = sed, group = segment), method = lm, fullrange = F, se = FALSE, alpha = 0.8,
            colour = 'red', linewidth = 1) +
  labs(y = "Growth rate (um/year)", x = "Age", title = turtle_ID) +
  theme_main(textsize_vsmall) +
  # theme_rem_xaxis + 
  theme(plot.margin = margin(7,7,0,7),
        legend.position = 'none') 
p_sed


```

```{r, echo = FALSE, message = FALSE, results = 'asis', warning = FALSE}

cpt_info <- classify_changepoints(turtle_dat = turtle_data$T13326,
                                  turtle_cpt_data = CPT_data_examples$T13326,
                                  cpt_class_criteria = cpt_classes,
                                  stable_segment_threshold = 5,
                                  major_change_threshold = 25) %>%
  mutate(CPT = seq(1,5,1)) %>% relocate(CPT) %>% arrange(desc(CPT))

# restab <- matrix(NA,nrow = nrow(cpt_info),ncol = 4) %>% 
#   data.frame() %>% 'colnames<-'(c('CPT','normalised rate change','classification', 'major change')) 
# restab$CPT <- rev(seq(1,5,1))
# restab$'normalised rate change' <- cpt_info$change_rate_norm
# restab$classification <- cpt_info$classification
# restab$'major change' <- cpt_info$major
# 
# restab <- restab %>% arrange(CPT)

knitr::kable(cpt_info)

```

The algorithm numbers the changepoints from youngest to oldest (reverse chronological).

Note that the rate change with time graphs are a bit deceptive in terms of identifying by eye whether changes are 'major' relative to one another (between segments). Angles between slopes will become exponentially smaller with greater rates as the line increasingly approaches the vertical (i.e. y = infinity * x or -infinity * x). As a result, small changes between small rates may appear more 'different' than large changes between large rates. See the transition across changepoint 1, above, which appears large but is in fact a relatively small change (and is classed as minor, i.e. representing <25 % of the total rate range in a year).

## Turtle population changes in growth rates

By summing the PDFs associated with positive (increasing) and negative (decreasing) changes in turtle growth rates, we are able to identify instances of increased change probability across the analysed turtle population, which will appear as pronounced peaks in the summed PDF distribution.

Note that the application of the 'major' threshold (changepoint growth rate rate deltas (um/year/year) must exceed >25 % of the total growth rate range of the turtle) decreases the number of changepoints across the turtles from 61 to 45. All comparisons made in the subsequent sections ignore minor changes (exclude the associated 16 changepoints).

### All turtles, all major changes

First, we can distinguish increasing from decreasing changepoints. This will reveal any pronounced peaks and whole-dataset patterns. 

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

#
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Which to ignore or exclude?
# for(i in seq_along(which(!is.na(turtle_res_log$Exclude)))){
#   print(turtle_res_log$Exclude[which(!is.na(turtle_res_log$Exclude))][i])
#   assignments[which(!is.na(turtle_res_log$Exclude))[i],turtle_res_log$Exclude[which(!is.na(turtle_res_log$Exclude))][i]+1] <- NA
# }

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_next %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Need to allow for multiple types

# Sort CPTs by type based on character matching


CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# 



# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "All changes") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Example caption: Summed PDFs representing the occurrence of major changes across all analysed turtles. Changes can be distinguished by their type, with increasing (decreasing) changepoints in red (blue) indicating that a turtle has transitioned to a period of faster (slower) growth.

Immediately there are a few things that leap out:

- There are three instances of decreasing changes that are followed by increasing changes, with a peak lag of ~9 months. This pattern is mirrored in the turtles themselves (e.g., look at the diagrams for T13992 and similar curves). 
- The decreasing changes are more frequent/common than increasing.

Significant overlap between increasing (n = 20) and decreasing (n = 25) changepoints. The lines correspond to the occurrence of changes representing any increase (speeding up) or decrease (slowing down) of growth rates. 

### All turtles, only major reversals

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

#
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Which to ignore or exclude?
# for(i in seq_along(which(!is.na(turtle_res_log$Exclude)))){
#   print(turtle_res_log$Exclude[which(!is.na(turtle_res_log$Exclude))][i])
#   assignments[which(!is.na(turtle_res_log$Exclude))[i],turtle_res_log$Exclude[which(!is.na(turtle_res_log$Exclude))][i]+1] <- NA
# }

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_next %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Need to allow for multiple types

# Sort CPTs by type based on character matching


CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, 
                                     assignments_short, type = c("increasing reversal","increasing complete reversal"))
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, 
                                     assignments_short, type = c("decreasing reversal","decreasing complete reversal"))

# 



# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "Reversals") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Next, it is useful to narrow down onto changes that are restricted to shifts between growth rate states - consistent rates ('stable'), increasing, and decreasing. These exclude changes 'within' states (i.e. alterations of slope in the same direction).

The lead/lag pattern between increasing (n cpts = 15) and decreasing (n cpts = 16) PDF sums holds true when restricted to only reversals, in this case excluding changepoints lying between segments both exhibiting increasing (or decreasing) growth rates, which are classed as 'accelerating' or 'stabilising' changes depending on whether the slope (rate in um/year/year) is increasing or decreasing in magnitude.

### All turtles, only major, complete reversals


```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

#
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Which to ignore or exclude?
# for(i in seq_along(which(!is.na(turtle_res_log$Exclude)))){
#   print(turtle_res_log$Exclude[which(!is.na(turtle_res_log$Exclude))][i])
#   assignments[which(!is.na(turtle_res_log$Exclude))[i],turtle_res_log$Exclude[which(!is.na(turtle_res_log$Exclude))][i]+1] <- NA
# }

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_next %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Need to allow for multiple types

# Sort CPTs by type based on character matching


CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, 
                                     assignments_short, type = c("increasing complete reversal"))
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, 
                                     assignments_short, type = c("decreasing complete reversal"))

# 



# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = 'Complete reversals') +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Here we restrict the PDFs to only 'complete' reversals - changepoints with a shift from increasing to decreasing growth rates and visa versa (transitions to or from stable states are ignored). The n cpts are greatly reduced, with only 1 complete increasing reversal and 8 decreasing complete reversals present. PDF peaks ~= 1 or less indicate their presence across 1 or fewer turtles (e.g., the decreasing peak in the above graph peaking towards the end of 2020).

The relative decrease in the numbers of changepoints of each type (increasing versus decreasing) indicates that the decreasing changes are more dramatic, with far fewer increasing changes manifesting as a clear shift back to increasing growth rates. Instead, most of the increasing reversals are more modest, and denote changes from decreasing to a stable state or stable to an increasing state. This is consistent with the individual turtle records showing sharp decreases - in most cases, periods of strongly decreasing growth rates are followed by a period of stagnant growth rates (i.e. a stable period).

## Species divisions 

As before, only major changepoints are included. All types of increasing and decreasing change are included in order to include as many changepoints as possible.

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# Trim assignments with exclusions
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Separate turtles into green
assignments_green <- assignments_next %>%
  filter(turtle %in% Turtle_info$ID[which(Turtle_info$Species == "Green")])

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_green %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Sort into increasing and decreasing
CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

## Plot
ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "Green turtles") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Green turtles. 9 turtles, 22 CPTs, 10 increasing, 12 decreasing.

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# Trim assignments with exclusions
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Separate turtles into green
assignments_logger <- assignments_next %>%
  filter(turtle %in% Turtle_info$ID[which(Turtle_info$Species == "Loggerhead")])

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_logger %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Sort into increasing and decreasing
CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

## Plot
ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "Loggerhead turtles") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Loggerheads. 11 turtles, 23 CPTs, 10 increasing, 13 decreasing.

## Regional divisions

Atlantic vs gulf

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# Trim assignments with exclusions
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Separate turtles into green
assignments_Atlantic <- assignments_next %>%
  filter(turtle %in% Turtle_info$ID[which(Turtle_info$Location == "Atlantic")])

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_Atlantic %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Sort into increasing and decreasing
CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

## Plot
ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "Atlantic turtles") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Atlantic. 14 turtles, 30 cpts, 11 increasing and 19 decreasing.

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# Trim assignments with exclusions
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Separate turtles into green
assignments_GOM <- assignments_next %>%
  filter(turtle %in% Turtle_info$ID[which(Turtle_info$Location == "GOM")])

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_GOM %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Sort into increasing and decreasing
CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

## Plot
ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "GOM turtles") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

GOM. 6 turtles, 15 cpts, 9 increasing, 6 decreasing.

## Sex differences

Male vs female

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# Trim assignments with exclusions
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Separate turtles into green
assignments_F <- assignments_next %>%
  filter(turtle %in% Turtle_info$ID[which(Turtle_info$Sex == "F")])

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_F %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Sort into increasing and decreasing
CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

## Plot
ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "Female turtles") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Female. 12 turtles, 27 CPTs, 13 increasing, 14 decreasing.

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 8, fig.width = 10, units = cm}

## Sed rates interpolated using linear and spline methods
# CPT_data <- get_CPT_files(paste0(proj_dir,"MCCPT-test-out/"))

# Now get the spreadsheet with the assigments
# turtle_res_log <- read.csv("Turtle-CPT-results-log.csv")

# # CPT assignments
# assignments <- turtle_res_log[,c(2,which(colnames(turtle_res_log) == "CPT.1"):which(colnames(turtle_res_log) == "CPT.5"))] %>%
#   mutate(across(c(2:6), ~ get_assignment(.)))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# Trim assignments with exclusions
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Separate turtles into green
assignments_M <- assignments_next %>%
  filter(turtle %in% Turtle_info$ID[which(Turtle_info$Sex == "M")])

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_M %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

## Sort into increasing and decreasing
CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)
# 
# plot(PDF_sum_increasing, type = 'l')
# plot(PDF_sum_decreasing, type = 'l')
# 

## Plot
ggplot() +
  geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type)) +
  scale_x_continuous(expand = c(0,0), limits = c(2005,2025), breaks = seq(2005,2025,5)) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Age",
       title = "Male turtles") +
  theme_main(textsize_vsmall) +
  theme(legend.position = 'inside',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"))

```

Male - 8 turtles, 18 CPTs, 7 increasing, 11 decreasing.

## Figures for publication

For the main text (2025-06 AAAS Science Advances manuscript ver), the analysis was distilled down to a single side-by-side stack figure showing all major changes alongside all major reversals, with the red tide and sargassum blooms shown as vertical bars.

```{r, echo=FALSE, message=FALSE, results='hide', warning = FALSE, fig.align = "left", fig.height = 7, fig.width = 16, units = cm}

# ALL MAJOR CHANGES

# Colours for final manuscript
# Refer to 'turtle-functions'
bg_col <- "#F2F2F2"
bgbdr_col <- "grey75"
tcol = "#58595B"

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# adjust assignments
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_next %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

# Sort CPTs by type based on character matching
CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "Increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "Decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)

p1 <- ggplot() +
  geom_hline(yintercept = seq(0,10,1), linetype = 'solid', colour = bgbdr_col) +
  geom_rect(aes(xmin = rt2018_start, xmax = rt2018_end, ymin = -Inf, ymax = Inf), fill = 'darkred', alpha = 0.2, colour = NA) +
  geom_rect(aes(xmin = sg2015_start, xmax = sg2015_end, ymin = -Inf, ymax = Inf), fill = 'goldenrod4', alpha = 0.2, colour = NA) +
  geom_rect(aes(xmin = sg2018_start, xmax = sg2018_end, ymin = -Inf, ymax = Inf), fill = 'goldenrod4', alpha = 0.2, colour = NA) +
  annotate(geom = "text", label = "Sargassum bloom", x = sg2015_end - 0.5*(sg2015_end - sg2015_start), y = 7, angle = 90, size = 13/.pt) +
  annotate(geom = "text", label = "Sargassum bloom + \n red tide", x = sg2018_end - 0.5*(sg2018_end - sg2018_start), y = 1.5, angle = 90, size = 13/.pt, lineheight = 0.9) +
  # geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type, linetype = type), size = 1) +
  scale_x_continuous(expand = c(0,0), limits = c(2008,2024), breaks = seq(2008,2024,2)) +
  scale_y_continuous(expand = c(0,0), limits = c(0, 10), breaks = seq(0,10,1)) +
  scale_linetype_manual(values = c("longdash","solid")) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = paste("Sum of Probability Distributions"), x = "Year", colour = "Type", linetype = "Type") +
  theme_main(textsize_small) +
  theme(legend.position = 'inside',
        legend.margin = margin(c(7,7,7,7)),
        legend.title = element_blank(),
        axis.title.y.left = element_text(),
        axis.title.y = element_text(),
        axis.title.x = element_blank(), ###
        legend.position.inside = c(0.728,0.92),
        legend.background = element_rect(fill = "white", colour = bgbdr_col),
        legend.box.background = element_rect(fill = "white"),
        legend.key.width = unit(1, "cm"),
        plot.margin = margin(10,7,25,7),
        panel.background = element_rect(fill = bg_col, 
                                        colour = bgbdr_col, 
                                        size = 0.5,
                                        linetype = 'solid'))

# MAJOR REVERSALS

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# adjust assignments
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_next %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

CPTs_increasing <- sort_CPTs_by_type(CPT_data_all, 
                                     assignments_short, type = c("increasing complete reversal"))
CPTs_decreasing <- sort_CPTs_by_type(CPT_data_all, 
                                     assignments_short, type = c("decreasing complete reversal"))

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "Increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "Decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)

p2 <- ggplot() +
  geom_hline(yintercept = seq(0,4,0.5), linetype = 'solid', colour = bgbdr_col) +
  geom_rect(aes(xmin = rt2018_start, xmax = rt2018_end, ymin = -Inf, ymax = Inf), fill = 'darkred', alpha = 0.2, colour = NA) +
  geom_rect(aes(xmin = sg2015_start, xmax = sg2015_end, ymin = -Inf, ymax = Inf), fill = 'goldenrod4', alpha = 0.2, colour = NA) +
  geom_rect(aes(xmin = sg2018_start, xmax = sg2018_end, ymin = -Inf, ymax = Inf), fill = 'goldenrod4', alpha = 0.2, colour = NA) +
  annotate(geom = "text", label = "Sargassum bloom", x = sg2015_end - 0.5*(sg2015_end - sg2015_start), y = 2.5, angle = 90, size = 13/.pt) +
  annotate(geom = "text", label = "Sargassum bloom + red tide", x = sg2018_end - 0.3*(sg2018_end - sg2018_start), y = 2.5, angle = 90, size = 13/.pt, lineheight = 0.9) +
  # geom_vline(xintercept = seq(2005,2025,1), linetype = 'dashed', colour = 'grey60') +
  geom_line(data = summed_PDFs, aes(x = age, y = PDF_sum, colour = type, linetype = type), size = 1) +
  scale_x_continuous(expand = c(0,0), limits = c(2008,2024), breaks = seq(2008,2024,2)) +
  scale_y_continuous(expand = c(0,0), limits = c(0, 4), breaks = seq(0,4,0.5), labels = c('0','0.5','1','1.5','2','2.5','3','3.5','4')) +
  scale_linetype_manual(values = c("longdash","solid")) +
  scale_colour_manual(values = c("blue","red")) +
  labs(y = "Sum of changepoint PDFs", x = "Year", colour = "Type", linetype = "Type") +
  theme_main(textsize_small) +
  theme(legend.position = 'none',
        legend.position.inside = c(0.2,0.8),
        legend.box.background = element_rect(colour = "white"),
        legend.key.width = unit(1, 'cm'),
        axis.title.y.left = element_blank(),
        axis.title.x = element_blank(), ###
        plot.margin = margin(10,21,25,21),
        panel.background = element_rect(fill = bg_col, 
                                        colour = bgbdr_col, 
                                        size = 0.5,
                                        linetype = 'solid'))

# grob for x. Thanks "J.Con" https://stackoverflow.com/questions/33114380/centered-x-axis-label-for-muliplot-using-cowplot-package
# x.grob <- textGrob("Common X", 
#                    gp=gpar(fontface="bold", col="blue", fontsize=15))

plot <- cowplot::plot_grid(p1,p2,
                   nrow = 1, ncol = 2, align = 'h',
                   labels = c("A","B"),
                   label_colour = tcol,
                   label_x = c(0.10,0.095),
                   label_y = c(0.98,0.98),
                   label_size = 25)
ggdraw(add_sub(plot, "Year", vpadding = grid::unit(0,"lines"),y = 5.5, x = 0.5, vjust = 4.5,
               color = tcol,size = textsize_normal))

```

Summed PDFs representing A) the occurrence of major changes across all analyzed turtles. Increasing changepoints (red, solid; n = 20) indicate an inflection towards higher growth rates. Decreasing changepoints (blue, dashed; n = 25) indicate the opposite, wherein a turtle has transitioned towards decreasing growth rates. B) Summed PDFs of major reversal changepoints across all analyzed turtles. Increasing (red, solid; n = 1) and decreasing (blue; n = 8) lines denote changepoint distributions in turtles that represent a shift from decreasing rates to increasing rates or vice versa, indicating a major change in the growth response of the turtle. 

