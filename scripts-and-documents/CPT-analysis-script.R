# Monte-carlo changepoints of turtle scute growth rates via radiocarbon dating

# Last updated 2025-06-24 
# Matt Harris
# m.harris@gns.cri.nz
# https://www.github.com/MRPHarris

# Written and run in:
#   Rstudio v2024.12.1
#   R v4.4.0
#   Windows 11 (Enterprise)

##### Description, setup #####

## Preamble
# This script generates all the data used for turtle changepoint analysis in
# Linscott & Wallace (202X). 
# The data processing occurs in a series of steps, starting from a set of oxcal
# program outputs generated by Dr. Bethan Linscott.
# For figures and an explainer of the analysis, refer to the manuscript and .Rmd
# file in this repository.

# The script is intended for use 'from scratch'. Some lines, e.g., package installs,
# can be hashed out if you already have them.

# This script should be opened from inside the R project found in the repository,
# so as to ensure the 'here' package correctly detects the intended filepath.

## A note on packages
# Two github packages are used. 
# The first is MCCPT (available here: https://github.com/h-cadd/MCCPT)
# The second is a dedicated helper package for this repository, turtleCPTs,
# which is available here: https://github.com/MRPHarris/turtleCPTs. This package
# contains all the underlying code that makes this repo 'tick'. 

## Download devtools
install.packages('devtools')

## detach + uninstall github packages. Use if you are updating/reinstalling them.
# detach(package:MCCPT, unload = TRUE) # Detach and unload (reverse 'library()') MCCPT
# installr::uninstall.packages("MCCPT") # Uninstall MCCPT

## Install github packages
devtools::install_github("hcadd/MCCPT@main")
devtools::install_github("MRPHarris/turtleCPTs@main")

## Pacman for package installs and loading
# install.packages('pacman')
library(pacman)
pacman::p_load(tidyverse, dplyr, magrittr, here, cowplot,
               pracma, scales, ggtext, RColorBrewer, ggtext,
               rlist, fs, matrixStats, openxlsx, MCCPT, changepoint, turtleCPTs)

## directories
proj_dir <- paste0(here(),"/") # Using 'here', which defaults to the project directory.
# setwd(proj_dir) # Shouldn't be necessary to specify the working directory as most of the code is explicit.
data_dir <- paste0(proj_dir,"data-raw/")
img_dir <- paste0(proj_dir,"images/")

## fns


##### 1  | Import turtle oxcal data #####

## Section notes
## Importing raw data.

## Generate list of files
turtle_files <- list.files(data_dir,full.names = T)[is_file(list.files(data_dir,full.names = T))]

## Generate list of datasets
tdat_list <- lapply(turtle_files, load_turtle_raw) %>%
  'names<-'(c(list.files(data_dir,full.names = F)[is_file(list.files(data_dir,full.names = T))]))

## Do these all have the same n ensembles?
if(length(unique(sapply(tdat_list,function(x){ncol(x$ens)}))) == 1){cat("yes")}else{cat("no")}

## How many observations, and what is the temporal coverage, for each turtle?
n_obs <- sapply(tdat_list,function(x){nrow(x$ens)}) %>%
  as.data.frame() %>% 'colnames<-'(c('n_obs')) %>%
  rownames_to_column('turtle') %>%
  mutate(turtle = unlist(lapply(strsplit(turtle,"_"),"[[",2))) %>%
  mutate(intcal20_t_min = sapply(tdat_list,function(x){min(x$cal$intcal20_t)})) %>%
  mutate(intcal20_t_max = sapply(tdat_list,function(x){max(x$cal$intcal20_t)})) %>%
  mutate(time_covered_years = intcal20_t_max - intcal20_t_min)

## What's the oldest age?
min(sapply(tdat_list,function(x){min(x$cal$intcal20_t)}))

##### 2  | Formatting data for MCCPT #####

## Section notes
# Data is coerced into a format appropriate for MCCPT. 
# To provide a consistent depth rate, all age model ensembles are interpolated
# to a uniform depth interval of 1 micron.

# Both linear and spline methods were experimented with. A monotonic spline was
# used for the published data (~2025-06 AAAS Science Advances version).

# Refer to the .Rmd file for a breakdown of how the code works, and 
# https://github.com/MRPHarris/turtleCPTs/R/ for the functions themselves 

# Now export for all sites!
# Long list for error checking
for(t in seq_along(tdat_list)){
  # message
  message(paste0("Formatting data for turtle ",t,"/",length(tdat_list)," | ",tdat_list[[t]]$ID))
  # export
  export_turtle_MCCPT(tdat_list[[t]],
                      output_directory = paste0(proj_dir,"data-for-MCCPT-sed/"),
                      convert_BP = 2025,
                      gradient = FALSE)
}

##### 2B | Plotting turtle growth rate data #####

## Section notes
# Per-turtle plots
turtle_cpt_fmt <- import_files(paste0(proj_dir,"data-for-MCCPT-sed/"))
for(t in seq_along(turtle_cpt_fmt)){
  message(t)
  plot_turtle_simple(turtle_cpt_fmt[[t]],
                     output_directory = paste0(proj_dir,"images-and-figures/turtle-sed-rate-images/R2L/"),
                     rev_x = T,
                     suffix = "R2L")
}

for(t in seq_along(turtle_cpt_fmt)){
  message(t)
  plot_turtle_simple(turtle_cpt_fmt[[t]],
                     output_directory = paste0(proj_dir,"images-and-figures/turtle-sed-rate-images/L2R/"),
                     rev_x = F,
                     suffix = "L2R")
}

##### 3  | Generating growth rate gradients #####

## Section notes
## Gradients provide a way to analyse the growth rates as distinct changes in slope, 
## rather than inflections in the raw growth rate data from oxcal.

for(t in seq_along(tdat_list)){
  # message
  message(paste0("Formatting data for turtle ",t,"/",length(tdat_list)," | ",tdat_list[[t]]$ID))
  # export
  export_turtle_MCCPT(tdat_list[[t]],
                      output_directory = paste0(proj_dir,"data-for-MCCPT-grads/"),
                      convert_BP = 2025,
                      gradient = TRUE,
                      grad_scale = c(0,100))
}

##### 4  | Monte-Carlo Changepoint Analysis (MCCPT) #####

## With the data now formatted, we can run the changepoints analysis.
# Analysis was performed on the gradient-converted data.

# Note that if you do re-run this code, it may overwrite the existing assignments.
# It is recommended to change the output directory if re-running the analysis in full.

# Get sites
# Might take a little bit!
turtle_cpt_fmt_g <- import_files(paste0(proj_dir,"data-for-MCCPT-grads/"))
turtle_cpt_subset <- turtle_cpt_fmt_g[1:20] # This is some legacy code; there are 20 turtles.

# Run the analysis using `MCCPT::conduct_MCCPT()`
conduct_MCCPT(turtle_cpt_subset,
              age_lowerbound = 2,
              age_upperbound = 17,
              output_folder = paste0(proj_dir,"results-MCCPT-changepoints/"),
              uncertainty_res = 1,
              cpt_calc = "mean")

##### 4B | Plotting turtle changepoint locations #####

## Plots with changepoints
turtle_data_struc <- import_files("data-for-MCCPT-sed/")
cpt_files <- get_CPT_files("results-MCCPT-changepoints/")
output_directory = paste0(proj_dir,"images-and-figures/turtle-changepoint-plots/")
export_CPT_plots(turtle_data = turtle_data_struc,
                 CPT_data = cpt_files,
                 suffix = "_allCPTs",
                 output_directory)

##### 5  | Classifying changepoints #####

## Section notes
# Consistent changepoint classification using set % inflection change in rate-rate (gradient).
turtle_data <- import_files("data-for-MCCPT-sed/")
CPT_data <- get_CPT_files("results-MCCPT-changepoints/")
criterion <- openxlsx::read.xlsx("results-MCCPT-logs-and-criteria/change-classification-criteria.xlsx",1)

# Major/minor is classified as changepoint rate difference exceeding 25% (normalised slope absolute value of >25)
# stable segments are defined as <+- 10% for segment rate
# classifications rely on the slopes of the segments bounding a changepoint and the sign of the changepoint rate change.

# Iterate through and do the assignments
class_turtle_list <- vector('list',length = length(turtle_data)) %>% 'names<-'(c(names(turtle_data)))
for(t in seq_along(class_turtle_list)){
  print(names(turtle_data)[t])
  class_turtle_list[[t]] <- classify_changepoints(turtle_dat = turtle_data[[t]],
                                                  turtle_cpt_data = CPT_data[[t]],
                                                  cpt_class_criteria = criterion,
                                                  stable_segment_threshold = 10,
                                                  major_change_threshold = 25) %>%
    mutate(turtle = names(turtle_data)[t])
}
turtles_all_classified <- rlist::list.rbind(class_turtle_list) %>%
  relocate(turtle,CPT,mean_age) %>% as.data.frame() %>% apply(.,2,as.character)

## Save!
write.csv(turtles_all_classified, paste0(proj_dir,"results-MCCPT-logs-and-criteria/turtle-changepoints-classified-10pct-stable.csv"),row.names = F)

##### 6  | Summing PDFs to identify periods of growth and stagnation #####

## Section notes 
# Working with PDFs!

# Get the CPT data
CPT_data <- get_CPT_files(paste0(proj_dir,"results-MCCPT-changepoints/"))

# Now get the spreadsheet with the assigments
assignments <- read.csv(paste0(proj_dir,"results-MCCPT-logs-and-criteria/turtle-changepoints-classified-10pct-stable.csv")) %>%
  mutate(exclusion_combos = paste0(turtle," ",CPT))

# Exclusions
exclusions <- matrix(NA,2,3) %>% data.frame() %>% 'colnames<-'(c('turtle','cpt_exclude','justification'))
exclusions$turtle <- c("T13776","T13987")
exclusions$cpt_exclude <- c("1","3")
exclusions$justification <- c("Too close to edge of data","Overlapping CPT. Without inclusion other changes did not manifest.")
exclusions$exclusion_combos = paste0(exclusions$turtle," ",exclusions$cpt_exclude)
# Very scuffed way of doing this as I am tired
exclude <- vector('logical', length = nrow(assignments))
exclude[c(which(assignments$exclusion_combos %in% exclusions$exclusion_combos))] <- TRUE

# adjust assignments
assignments_next <- assignments %>%
  mutate(exclude = exclude) %>%
  dplyr::select(-c(exclusion_combos)) %>%
  filter(!exclude) %>% dplyr::select(-c(exclude))

# Exclude minor changepoints
assignments_next <- assignments_next %>%
  filter(major)

# Conform to previous format - wide, because it made sense at the time
assignments_short <- assignments_next %>% select(turtle,CPT,classification) %>%
  pivot_wider(names_from = CPT, values_from  = classification, names_sort = T) %>%
  'colnames<-'(c('turtle','CPT.1','CPT.2','CPT.3','CPT.4','CPT.5'))

# Sort CPTs by type based on character matching
CPTs_increasing <- sort_CPTs_by_type(CPT_data, assignments_short, type = "increasing")
CPTs_decreasing <- sort_CPTs_by_type(CPT_data, assignments_short, type = "decreasing")

# Now sum them! 
PDF_sum_increasing <- sum_PDFs(CPTs_increasing) %>% mutate(type = "Increasing")
PDF_sum_decreasing <- sum_PDFs(CPTs_decreasing) %>% mutate(type = "Decreasing")
summed_PDFs <- rbind(PDF_sum_increasing,PDF_sum_decreasing)

plot(PDF_sum_increasing %>% select(-c(type)), type = 'l')
plot(PDF_sum_decreasing %>% select(-c(type)), type = 'l')
